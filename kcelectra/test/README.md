# 🧪 KcELECTRA 분류 성능 개선 실험

> **오탐(FP)** 과 **미탐(FN)** 을 줄여 전체 분류 성능을 개선하기 위한 실험들

### 용어 정리
- **오탐(FP, False Positive)**: 정상 문장을 악성으로 잘못 분류
- **미탐(FN, False Negative)**: 악성 문장을 정상으로 잘못 분류

### 목표
- **오탐(FP)** 과 **미탐(FN)** 을 동시에 줄인다.
- 단순 Accuracy가 아닌 **Precision/Recall 균형**, **F1 Score** 를 함께 관리한다.
- 특히 **변형 욕설(초성, 숫자 치환 등)** 탐지율을 높인다.

---

## 📋 실험 목록

| 실험 ID | 파일명 | 변경 사항 | 기대 효과 |
|---------|--------|----------|----------|
| **E1** | `E1_threshold_tuning.ipynb` | threshold 스윕 (0.1~0.95) | FP/FN 균형 조절 (재학습 없이) |
| **E2** | `E2_precision_metric.ipynb` | metric_for_best_model = precision | Precision ↑, FP ↓ |
| **E3** | `E3_loss_weight_FP.ipynb` | class_weights 조정 | FP/FN 벌점 조정 |
| **E4** | `E4_data_augmentation.ipynb` | LOL 욕설 + 특수문자 정상 데이터 증강 | 일반 욕설 탐지↑, FP↓ |
| **E5** | (예정) | E4 + 가중치 반영 (1:5) | 희소 클래스 보정 |

---

## 🚀 현재 실험 중인 내용용

```
1. E4 (데이터 증강) - LOL 욕설 + 특수문자 정상
   ↓
2. E5 (E4 + 가중치 1:5) - E4가 잘 나오면
   ↓
3. Threshold 튜닝 (0.7 기준)
```

---

## 📂 폴더 구조

```
test/
├── README.md                    # 이 파일
├── 모델비교_테스트.ipynb         # 모델 비교 평가 (테스트 문장)
├── E1_threshold_tuning.ipynb    # 실험 1: Threshold 스윕
├── E2_precision_metric.ipynb    # 실험 2: Precision 기준
├── E3_loss_weight_FP.ipynb      # 실험 3: Loss 가중치 조정
│
├── E1_output/                   # E1 결과물 (자동 생성)
│   ├── best_model/
│   └── threshold_sweep_results.csv
├── E2_output/                   # E2 결과물 (자동 생성)
│   └── best_model/
└── E3_output/                   # E3 결과물 (자동 생성)
    └── best_model_E3-?/
```

---

## 📊 실험 비교표 (Validation 기준)

| 실험 | FP (오탐) | FN (미탐) | Precision | Recall | F1 | 비고 |
|------|-----------|-----------|-----------|--------|-----|------|
| **기존 (baseline)** | - | - | **93.21%** | **89.78%** | **91.46%** | KcElectra_학습.ipynb, AUC=98.09% |
| E1 (th=0.5) | | | | | | |
| E1 (th=최적) | | | | | | |
| E2 (precision) | 223 | - | 93.22% | 89.54% | 91.35% | AUC=98.07% |
| **E3-R (w1=4, 실제비율)** | | | | | | 권장: 욕설:정상=1:4 반영 |
| E3-R2 (w1=2) | | | | | | 실제비율 약하게 |
| E3-1 (w0=1.5, FP↓) | | | | | | |
| E3-3 (w1=1.5, FN↓) | | | | | | |
| **E4 (데이터증강)** | | | | | | LOL욕설+특수문자정상 |
| E5 (E4+가중치) | | | | | | 예정 |

---

## 🎯 테스트 문장 평가 결과

> `모델비교_테스트.ipynb`에서 동일한 테스트 문장(27개)으로 평가한 결과

### 테스트 데이터 구성
| 카테고리 | 개수 | 설명 |
|----------|------|------|
| 정상-일반 | 5 | 일반적인 정상 문장 |
| 정상-하드네거티브 | 4 | 초성/은어 포함 (정상) |
| 정상-하드카운터 | 6 | 특수문자/짧은 문장 |
| 악성-일반욕설 | 5 | 명확한 욕설 |
| 악성-변형욕설 | 7 | 초성/숫자 치환 욕설 |

### 모델별 테스트 결과

| 모델 | Threshold | Acc | Precision | Recall | F1 | FP | FN |
|------|-----------|-----|-----------|--------|----|----|-----|
| Baseline | 0.5 | | | | | | |
| E1 (th=최적) | | | | | | | |
| E2 | 0.5 | | | | | | |
| E3-? | 0.5 | | | | | | |

### 카테고리별 정확도

| 카테고리 | Baseline | E1 | E2 | E3-? |
|----------|----------|-----|-----|------|
| 정상-일반 | | | | |
| 정상-하드네거티브 | | | | |
| 정상-하드카운터 | | | | |
| 악성-일반욕설 | | | | |
| 악성-변형욕설 | | | | |

---

## ⚠️ 주의사항

1. **데이터 경로**: 각 노트북에서 `DATA_DIR`이 `../data`로 설정되어 있음
2. **GPU 권장**: 학습에 시간이 오래 걸리므로 GPU 환경 권장
3. **실험 순서**: E1은 재학습 없이 빠르게 테스트 가능, E2/E3는 재학습 필요

---

## 📝 결과 기록 템플릿

```markdown
#### 실험 ID: E?
- 변경 사항:
  - (예) threshold 0.5→0.72
  - (예) class weight [1.5, 0.5]
- Validation 성능:
  - FP(오탐, 정상→악성): 
  - FN(미탐, 악성→정상): 
  - Precision:
  - Recall:
  - F1:
- 코멘트:
  - 오탐(FP)이 주로 발생한 문장 유형:
  - 미탐(FN)이 주로 발생한 문장 유형:
```

---

## 🔮 추가 실험 계획 (미구현)

### E4: 하드 케이스 데이터 보강
- **하드 네거티브**: FP 사례(정상인데 욕/은어/밈 포함)를 정상 라벨로 추가
- **하드 포지티브**: FN 사례(변형 욕설)를 악성 라벨로 추가
- 목표: 경계 사례에서 분류 성능 향상

### E5: 변형 욕설 데이터 증강
- 초성 변환, 숫자 치환(시발→ㅅㅂ, 18 등) 패턴 학습 강화
- LOL 욕설 데이터(`data/LOL_badwords_all_merged.csv`) 추가
- 목표: 변형 욕설 미탐(FN) 감소

### E6: 캘리브레이션 + threshold 재튜닝
- Temperature scaling 등으로 과신 완화
- 확률 분포 보정 후 threshold 재튜닝
- 목표: 애매한 케이스에서 더 정확한 판단

---

## 📊 모델비교_테스트.ipynb 결과

> 27개 테스트 문장으로 평가한 결과 (Baseline, E1, E2)

### 모델 비교 요약

| 모델 | Threshold | Accuracy | Precision | Recall | F1 | FP(오탐) | FN(미탐) | FPR |
|------|-----------|----------|-----------|--------|-----|---------|---------|-----|
| Baseline | 0.5 | 48.1% | 40.0% | 33.3% | 36.4% | 6 | 8 | 40.0% |
| E1 (Threshold 튜닝) | 0.9 | 40.7% | 16.7% | 8.3% | 11.1% | 5 | 11 | 33.3% |
| E2 (Precision 최적화) | 0.5 | 44.4% | 33.3% | 25.0% | 28.6% | 6 | 9 | 40.0% |

### 카테고리별 정확도 비교

| 카테고리 | 개수 | Baseline | E1 | E2 |
|----------|------|----------|-----|-----|
| 정상-일반 | 5 | 80% | 100% | 80% |
| 정상-하드네거티브 | 4 | 75% | 75% | 75% |
| 정상-하드카운터 | 6 | 33% | 33% | 33% |
| 악성-일반욕설 | 5 | 40% | 0% | 40% |
| 악성-변형욕설 | 7 | 29% | 14% | 14% |

### 분석 결과

1. **일반 욕설 탐지 부족**: 변형 욕설에 집중하다 보니 일반 욕설 탐지율이 낮음
2. **특수문자 오탐**: `@`, `^`, `*` 등 특수문자를 욕설로 오판하는 경향
3. **하드카운터 취약**: 특수문자/짧은 문장에서 모든 모델이 33%로 낮은 성능

### 개선 방향 (E4, E5)

- **E4**: LOL 욕설 데이터 + 특수문자 정상 데이터 증강
- **E5**: E4 기반 + 가중치 반영 (욕설:정상 = 1:5)
- **Threshold 튜닝**: 데이터 증강 후 0.7 기준으로 재조정
