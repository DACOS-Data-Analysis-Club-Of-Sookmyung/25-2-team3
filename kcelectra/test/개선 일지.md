# 🧪 KcELECTRA 분류 성능 개선 실험

> **오탐(FP)** 과 **미탐(FN)** 을 줄여 전체 분류 성능을 개선하기 위한 실험들

### 용어 정리
- **오탐(FP, False Positive)**: 정상 문장을 악성으로 잘못 분류
- **미탐(FN, False Negative)**: 악성 문장을 정상으로 잘못 분류

### 목표
- **오탐(FP)** 과 **미탐(FN)** 을 동시에 줄인다.
- 단순 Accuracy가 아닌 **Precision/Recall 균형**, **F1 Score** 를 함께 관리한다.
- 특히 **변형 욕설(초성, 숫자 치환 등)** 탐지율을 높인다.

---

## 📋 실험 목록

| 실험 ID | 파일명 | 변경 사항 | 기대 효과 |
|---------|--------|----------|----------|
| **E1** | `E1_threshold_tuning.ipynb` | threshold 스윕 (0.1~0.95) | FP/FN 균형 조절 (재학습 없이) |
| **E2** | `E2_precision_metric.ipynb` | metric_for_best_model = precision | Precision ↑, FP ↓ |
| **E3** | `E3_loss_weight_FP.ipynb` | class_weights 조정 | FP/FN 벌점 조정 |
| **E4** | `E4_data_augmentation.ipynb` | LOL 욕설 + 특수문자 정상 데이터 증강 | 일반 욕설 탐지↑, FP↓ |
| **E5** | `E5_augment_weight.ipynb` | E4 + 가중치 반영 (4:1) | FP 추가 감소, 실제 비율 반영 |

---

## ✅ 실험 완료 현황

```
✅ E1 (Threshold 튜닝) - 완료
✅ E2 (Precision 메트릭) - 완료
✅ E4 (데이터 증강) - 완료, F1 95.13% 달성
✅ E5 (E4 + 가중치 4:1) - 완료, FP 최소화
```

> **최종 권장 모델**: E4 (균형 잡힌 성능) 또는 E5 (FP 최소화)

---

## 📂 폴더 구조

```
test/
├── README.md                    # 이 파일
├── 모델비교_테스트.ipynb         # 모델 비교 평가 (테스트 문장)
├── E1_threshold_tuning.ipynb    # 실험 1: Threshold 스윕
├── E2_precision_metric.ipynb    # 실험 2: Precision 기준
├── E3_loss_weight_FP.ipynb      # 실험 3: Loss 가중치 조정
├── E4_data_augmentation.ipynb   # 실험 4: 데이터 증강
├── E5_augment_weight.ipynb      # 실험 5: E4 + 가중치 (4:1)
│
├── E1_output/                   # E1 결과물 (.gitignore)
├── E2_output/                   # E2 결과물 (.gitignore)
├── E3_output/                   # E3 결과물 (.gitignore)
├── E4_output/                   # E4 결과물 (.gitignore)
└── E5_output/                   # E5 결과물 (.gitignore)
```

---

## 📊 실험 비교표 (Validation 기준)

| 실험 | FP (오탐) | FN (미탐) | Precision | Recall | F1 | 비고 |
|------|-----------|-----------|-----------|--------|-----|------|
| 기존 (baseline) | - | - | 93.21% | 89.78% | 91.46% | KcElectra_학습.ipynb, AUC=98.09% |
| E1 (th=0.5) | 247 | 287 | 92.70% | 91.63% | 92.16% | FPR=5.40% |
| E1 (th=0.90) | 79 | 594 | 97.28% | 82.65% | 89.37% | FPR=1.73%, FP최소(Recall≥0.8) |
| E2 (precision) | 223 | 358 | 93.22% | 89.54% | 91.35% | AUC=98.07% |
| E4 (데이터증강) | 247 | 331 | 95.81% | 94.46% | 95.13% | AUC=98.88%, LOL욕설+특수문자정상 |
| E5 (E4+가중치) | 222 | 378 | 96.19% | 93.68% | 94.92% | AUC=98.70%, class_weight=[4,1] |

---

## ⚠️ 주의사항

1. **데이터 경로**: 각 노트북에서 절대 경로 사용 (환경에 맞게 수정 필요)
2. **GPU 권장**: 학습에 시간이 오래 걸리므로 GPU 환경 권장 (E4/E5: 약 1.5~2시간)
3. **실험 순서**: E1은 재학습 없이 빠르게 테스트 가능, E2~E5는 재학습 필요
4. **모델 출력**: `*_output/` 폴더는 `.gitignore`에 포함되어 Git에 업로드되지 않음

---

## 📝 결과 기록 템플릿

```markdown
#### 실험 ID: E?
- 변경 사항:
  - (예) threshold 0.5→0.72
  - (예) class weight [1.5, 0.5]
- Validation 성능:
  - FP(오탐, 정상→악성): 
  - FN(미탐, 악성→정상): 
  - Precision:
  - Recall:
  - F1:
- 코멘트:
  - 오탐(FP)이 주로 발생한 문장 유형:
  - 미탐(FN)이 주로 발생한 문장 유형:
```

---

## 🔮 추가 실험 계획 (미구현)

### E6: 하드 케이스 데이터 보강
- **하드 네거티브**: FP 사례(정상인데 욕/은어/밈 포함)를 정상 라벨로 추가
- **하드 포지티브**: FN 사례(변형 욕설)를 악성 라벨로 추가
- 목표: 경계 사례에서 분류 성능 향상

### E7: 캘리브레이션 + threshold 재튜닝
- Temperature scaling 등으로 과신 완화
- 확률 분포 보정 후 threshold 재튜닝
- 목표: 애매한 케이스에서 더 정확한 판단

> **참고**: LOL 욕설 데이터 증강은 E4에서 구현 완료

---

## 📊 모델비교_테스트.ipynb 결과

> 30개 테스트 문장으로 평가한 결과 (Baseline, E1, E2, E4, E5)

### 모델 비교 요약

| 모델 | Threshold | Accuracy | Precision | Recall | F1 | FP(오탐) | FN(미탐) | FPR |
|------|-----------|----------|-----------|--------|-----|---------|---------|-----|
| Baseline | 0.5 | 50.0% | 50.0% | 33.3% | 40.0% | 5 | 10 | 33.3% |
| E1 (Threshold 튜닝) | 0.9 | 43.3% | 33.3% | 13.3% | 19.0% | 4 | 13 | 26.7% |
| E2 (Precision 최적화) | 0.5 | 46.7% | 44.4% | 26.7% | 33.3% | 5 | 11 | 33.3% |
| E4 (데이터 증강) | 0.5 | 66.7% | 72.7% | 53.3% | 61.5% | 3 | 7 | 20.0% |
| E5 (증강+가중치) | 0.5 | 66.7% | 77.8% | 46.7% | 58.3% | 2 | 8 | 13.3% |

### 카테고리별 정확도 비교

| 카테고리 | 개수 | Baseline | E1 | E2 | E4 | E5 |
|----------|------|----------|-----|-----|--------|--------|
| 정상-일반 | 5 | 80% | 100% | 80% | 80% | 100%** |
| 정상-하드네거티브 | 5 | 80% | 80% | 80% | 80% | 80% |
| 정상-하드카운터 | 5 | 40% | 40% | 40% | 80% | 80% |
| 악성-일반욕설 | 5 | 40% | 0% | 40% | 80% | 40% |
| 악성-변형욕설 | 10 | 30% | 20% | 20% | 40% | 50% |

### 분석 결과

1. **E4가 최고 F1**: Accuracy/F1 66.7%/61.5%, Recall 53.3%로 가장 균형적.
2. **E5는 FP 최소**: FP=2, FPR 13.3%로 최저이지만 Recall 46.7%로 E4 대비 하락.
3. **하드카운터·정상 개선**: E4/E5 모두 정상-하드카운터 80%까지 개선(기존 40%).
4. **변형 욕설 개선 폭 제한**: E5 50% > E4 40%이지만 전체 Recall이 낮아 FN이 8건.

### 결론

- **FP 최소화 목표**: E5 선택 (FP=2, FPR=13.3%)
- **균형 잡힌 성능**: E4 선택 (F1=61.5%, 가장 높음)
- **추가 개선**: E5 기반 Threshold 튜닝 또는 E4/E5 앙상블로 FN 보완 검토
